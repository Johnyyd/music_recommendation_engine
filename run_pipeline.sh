#!/bin/bash
set -e  # Exit on error

# Cáº¥u hÃ¬nh
node="172.19.67.26" # "node1"
timestamp=$(date +%Y%m%d_%H%M%S)
log_dir="logs"
log_file="${log_dir}/pipeline_${timestamp}.log"

# Táº¡o thÆ° má»¥c logs náº¿u chÆ°a tá»“n táº¡i
mkdir -p $log_dir

# Äáº£m báº£o thÆ° má»¥c táº¡m cho Spark tá»“n táº¡i
mkdir -p /tmp/spark || true
hdfs dfs -mkdir -p /tmp/spark_checkpoints || true

# HÃ m log
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a "$log_file"
}

# HÃ m kiá»ƒm tra exit code
check_status() {
    if [ $? -ne 0 ]; then
        log "âŒ ERROR: Step $1 failed"
        exit 1
    fi
}

# Backup dá»¯ liá»‡u hiá»‡n cÃ³
log "=== [0/5] Backing up existing data ==="
hdfs dfs -test -d /data/mqd/parquet && {
    backup_dir="/data/mqd/backup/parquet_${timestamp}"
    hdfs dfs -mv /data/mqd/parquet $backup_dir
    log "âœ“ Backed up parquet data to $backup_dir"
} || log "No existing parquet data to backup"

# Pipeline chÃ­nh
log "=== [1/5] ETL JSON â†’ Parquet ==="
HDFS_NODE="$node" spark-submit --master spark://$node:7077 /mnt/c/LUUDULIEU/CODE/github/music_recommendation_engine/etl_to_parquet.py
check_status "ETL"

log "=== [2/5] Split Train/Test Data ==="
HDFS_NODE="$node" spark-submit --master spark://$node:7077 /mnt/c/LUUDULIEU/CODE/github/music_recommendation_engine/split_train_test.py
check_status "Data Split"

log "=== [3/5] Train ALS Model ==="
HDFS_NODE="$node" spark-submit \
  --master spark://$node:7077 \
  --conf spark.executor.memory=4g \
  --conf spark.executor.memoryOverhead=1g \
  --conf spark.driver.memory=2g \
  --conf spark.executor.cores=2 \
  --conf spark.sql.shuffle.partitions=64 \
  --conf spark.default.parallelism=64 \
  --conf spark.speculation=true \
  --conf spark.task.maxFailures=8 \
  --conf spark.reducer.maxSizeInFlight=48m \
  --conf spark.local.dir=/tmp/spark \
  /mnt/c/LUUDULIEU/CODE/github/music_recommendation_engine/train_als_model.py
check_status "Training"

log "=== [4/5] Evaluate Model ==="
HDFS_NODE="$node" spark-submit \
--master spark://$node:7077 \
--conf spark.executor.memory=5g \
--conf spark.executor.memoryOverhead=1g \
--conf spark.driver.memory=2g \
--conf spark.executor.cores=2 \
--conf spark.sql.shuffle.partitions=64 \
--conf spark.default.parallelism=64 \
--conf spark.speculation=true \
--conf spark.task.maxFailures=8 \
--conf spark.reducer.maxSizeInFlight=48m \
--conf spark.local.dir=/tmp/spark \
/mnt/c/LUUDULIEU/CODE/github/music_recommendation_engine/evaluation.py
check_status "Evaluation"

log "=== [5/5] Generate Submission ==="
HDFS_NODE="$node" spark-submit \
--master spark://$node:7077 \
--conf spark.executor.memory=4g \
--conf spark.executor.memoryOverhead=1g \
--conf spark.driver.memory=2g \
--conf spark.executor.cores=2 \
--conf spark.sql.shuffle.partitions=128 \
--conf spark.default.parallelism=128 \
--conf spark.speculation=true \
--conf spark.task.maxFailures=8 \
--conf spark.reducer.maxSizeInFlight=48m \
--conf spark.local.dir=/tmp/spark \
/mnt/c/LUUDULIEU/CODE/github/music_recommendation_engine/generate_submission.py
check_status "Submission Generation"

log "âœ… Pipeline completed successfully!"

# LÆ°u metrics vÃ o file
metrics_file="${log_dir}/metrics_history.csv"
if [ ! -f "$metrics_file" ]; then
    echo "timestamp,map_score,num_playlists,training_time" > "$metrics_file"
fi

# Láº¥y MAP score tá»« log file
map_score=$(grep "Mean Average Precision @ 500:" "$log_file" | tail -n1 | awk '{print $NF}')
echo "${timestamp},${map_score},$num_playlists,$SECONDS" >> "$metrics_file"

log "ğŸ“Š Metrics saved to ${metrics_file}"
