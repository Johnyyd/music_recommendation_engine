#!/bin/bash
set -e  # Exit on error

# Cáº¥u hÃ¬nh
node="172.19.67.26" # "node1"
timestamp=$(date +%Y%m%d_%H%M%S)
log_dir="logs"
log_file="${log_dir}/pipeline_${timestamp}.log"

# Táº¡o thÆ° má»¥c logs náº¿u chÆ°a tá»“n táº¡i
mkdir -p $log_dir

# HÃ m log
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1" | tee -a "$log_file"
}

# HÃ m kiá»ƒm tra exit code
check_status() {
    if [ $? -ne 0 ]; then
        log "âŒ ERROR: Step $1 failed"
        exit 1
    fi
}

# Backup dá»¯ liá»‡u hiá»‡n cÃ³
log "=== [0/5] Backing up existing data ==="
hdfs dfs -test -d /data/mpd/parquet && {
    backup_dir="/data/mpd/backup/parquet_${timestamp}"
    hdfs dfs -mv /data/mpd/parquet $backup_dir
    log "âœ“ Backed up parquet data to $backup_dir"
} || log "No existing parquet data to backup"

# Pipeline chÃ­nh
log "=== [1/5] ETL JSON â†’ Parquet ==="
spark-submit --master spark://$node:7077 etl_to_parquet.py
check_status "ETL"

log "=== [2/5] Split Train/Test Data ==="
spark-submit --master spark://$node:7077 split_train_test.py
check_status "Data Split"

log "=== [3/5] Train ALS Model ==="
spark-submit --master spark://$node:7077 train_als_model.py
check_status "Training"

log "=== [4/5] Evaluate Model ==="
spark-submit --master spark://$node:7077 evaluation.py
check_status "Evaluation"

log "=== [5/5] Generate Submission ==="
spark-submit --master spark://$node:7077 generate_submission.py
check_status "Submission Generation"

log "âœ… Pipeline completed successfully!"

# LÆ°u metrics vÃ o file
metrics_file="${log_dir}/metrics_history.csv"
if [ ! -f "$metrics_file" ]; then
    echo "timestamp,map_score,num_playlists,training_time" > "$metrics_file"
fi

# Láº¥y MAP score tá»« log file
map_score=$(grep "Mean Average Precision @ 500:" "$log_file" | tail -n1 | awk '{print $NF}')
echo "${timestamp},${map_score},$num_playlists,$SECONDS" >> "$metrics_file"

log "ğŸ“Š Metrics saved to ${metrics_file}"
